worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    include /usr/local/openresty/nginx/conf/mime.types;
    default_type application/json;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time backend=$upstream_addr';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 1000;

    # Shared memory for caching backend IPs
    lua_shared_dict backend_cache 1m;

    # Initialize background refresh of backend IPs
    init_worker_by_lua_block {
        local function refresh_backends()
            -- TODO: Query Postgres for current leader/follower IPs
            -- For now, use static values
            ngx.shared.backend_cache:set("leader", "172.17.0.1:12347")
            ngx.shared.backend_cache:set("follower", "172.17.0.1:23456")
            
            -- Schedule next refresh
            local ok, err = ngx.timer.at(0.2, refresh_backends)
            if not ok then
                ngx.log(ngx.ERR, "failed to schedule backend refresh: ", err)
            end
        end
        
        -- Start the refresh timer
        ngx.timer.at(0, refresh_backends)
    }

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        application/json
        text/plain
        text/css
        application/javascript
        text/xml
        application/xml
        application/xml+rss
        text/javascript;

    # Buffer sizes
    client_body_buffer_size 128k;
    client_max_body_size 10m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 4k;

    # DNS resolver for dynamic proxy_pass
    resolver 127.0.0.11 valid=10s;
    
    # Proxy settings
    proxy_buffering on;
    proxy_buffer_size 64k;
    proxy_buffers 8 64k;
    proxy_busy_buffers_size 128k;
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    server {
        listen 80;
        server_name _;

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Main proxy location with dynamic backend selection
        location / {
            set $backend '';
            
            access_by_lua_block {
                local uri = ngx.var.uri
                local method = ngx.var.request_method
                local backend_cache = ngx.shared.backend_cache
                
                -- Route /sequencer/txs POSTs to leader
                if uri == "/sequencer/txs" and method == "POST" then
                    ngx.var.backend = backend_cache:get("leader") or "172.17.0.1:12347"
                else
                    -- Route all other requests to follower (fallback to leader if no follower)
                    ngx.var.backend = backend_cache:get("follower") or 
                                     backend_cache:get("leader") or 
                                     "172.17.0.1:23456"
                end
            }
            
            proxy_pass http://$backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket support
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;

            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }
    }

    # WebSocket connection upgrade map
    map $http_upgrade $connection_upgrade {
        default upgrade;
        '' close;
    }
}
